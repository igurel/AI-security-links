# AI security related links
## ENISA (The European Network and Information Security Agency)
* [AI Threat Landscape Report](https://www.enisa.europa.eu/publications/artificial-intelligence-cybersecurity-challenges)
* [Artificial Intelligence Cybersecurity Challenges](https://www.enisa.europa.eu/publications/artificial-intelligence-cybersecurity-challenges)
* [Artificial Intelligence: How to make Machine Learning Cyber Secure?](https://www.enisa.europa.eu/news/artificial-intelligence-how-to-make-machine-learning-cyber-secure)
* [Securing Machine Learning Algorithms](https://www.enisa.europa.eu/publications/securing-machine-learning-algorithms)

## ETSI (The European Telecommunications Standards Institute)
* [Securing Artificial Intelligence (SAI) Mitigation Strategy Report](https://www.etsi.org/deliver/etsi_gr/SAI/001_099/005/01.01.01_60/gr_SAI005v010101p.pdf)

## Microsoft
* [AI/ML Pivots to the Security Development Lifecycle Bug Bar](https://docs.microsoft.com/en-us/security/engineering/bug-bar-aiml)
* [AI security risk assessment using Counterfit](https://www.microsoft.com/security/blog/2021/05/03/ai-security-risk-assessment-using-counterfit/)
* [A holistic approach to PPML (Privacy Preserving ML)](https://www.microsoft.com/en-us/research/group/privacy-preserving-machine-learning-innovation/)
* [Confidential AI - Confidential ONNX Inference Server](https://github.com/microsoft/onnx-server-openenclave)
* [Counterfit](https://github.com/Azure/counterfit/)
* [Failure Modes in Machine Learning](https://docs.microsoft.com/en-us/security/engineering/failure-modes-in-machine-learning)
* [Practical application of artificial intelligence that can transform cybersecurity](https://www.microsoft.com/security/blog/2018/09/05/practical-application-of-artificial-intelligence-that-can-transform-cybersecurity/)
* [Privacy Preserving Machine Learning: Maintaining confidentiality and preserving trust](https://www.microsoft.com/en-us/research/blog/privacy-preserving-machine-learning-maintaining-confidentiality-and-preserving-trust/)
* [Securing the Future of Artificial Intelligence and Machine Learning at Microsoft](https://docs.microsoft.com/en-us/security/engineering/securing-artificial-intelligence-machine-learning)
* [Threat Modeling AI/ML Systems and Dependencies](https://docs.microsoft.com/en-us/security/engineering/threat-modeling-aiml)

## MITRE 
* [MITRE - Adversarial ML 101](https://github.com/mitre/advmlthreatmatrix/blob/master/pages/adversarial-ml-101.md#adversarial-machine-learning-101)
* [MITRE - Adversarial ML Threat Matrix](https://github.com/mitre/advmlthreatmatrix/)
* [MITRE ATLAS, Adversarial Threat Landscape for Artificial-Intelligence Systems](https://atlas.mitre.org/)

## NIST (The National Institute of Standards and Technology)
* [NISTIR 8332 - Trust and Artificial Intelligence](https://www.nist.gov/publications/trust-and-artificial-intelligence)
* [NISTIR 8269 - A Taxonomy and Terminology of Adversarial Machine Learning](https://csrc.nist.gov/publications/detail/nistir/8269/draft)

## Articles
* [Deep Learning with Differential Privacy - Abadi et al](https://arxiv.org/abs/1607.00133)
* [Dos and Don'ts of Machine Learning in Computer Security - Arp et al](https://arxiv.org/abs/2010.09470)
* [Entangled Watermarks as a Defense against Model Extraction - Jia et al](https://arxiv.org/abs/2002.12200)
* [Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning - Jagielski et al](https://arxiv.org/abs/1804.00308)
* [On Adaptive Attacks to Adversarial Example Defenses - Florian Tramer et al](https://arxiv.org/abs/2002.08347) -- [[slides]](https://www.usenix.org/system/files/scainet20_2_slides_tramer.pdf) [[video]](https://youtu.be/ZFdtBA4eAgc)
* [Practical Black-Box Attacks against Machine Learning - Papernot et al](https://arxiv.org/abs/1602.02697)
* [Privacy-Preserving Machine Learning: Methods, Challenges and Directions - R Xu et al](https://arxiv.org/abs/2108.04417)

## Blogs
* [F-Secure AI Security Blog](https://blog.f-secure.com/artificial-intelligence-cyber-security/)
* [Google AI Blog](https://ai.googleblog.com/)
* [OpenAI Blog](https://openai.com/blog/)
* [Microsoft Security Blog - AI/ML](https://www.microsoft.com/security/blog/ai-and-machine-learning/)

## E-books
* [The Coming AI Hackers, Bruce Schneier](https://www.schneier.com/wp-content/uploads/2021/04/The-Coming-AI-Hackers.pdf)

## Other links
* [Adversarial Robustness Toolbox](https://github.com/Trusted-AI/adversarial-robustness-toolbox)
* [DARPA GARD (Guaranteeing AI Robustness to Deception) Project](https://www.gardproject.org/)
* [Europol: Malicious Uses and Abuses of Artificial Intelligence](https://www.europol.europa.eu/publications-events/publications/malicious-uses-and-abuses-of-artificial-intelligence)
* [NVIDIA Developer Blog - Federated Learning with Homomorphic Encryption](https://developer.nvidia.com/blog/federated-learning-with-homomorphic-encryption/)
* [NVIDIA Morpheus AI Cybersecurity Framework](https://developer.nvidia.com/morpheus-cybersecurity)
* [PyTorch PPML Framework Tutorial](https://graphene.readthedocs.io/en/latest/tutorials/pytorch/index.html)
* [Stealing Machine Learning Models via Prediction API](https://www.usenix.org/system/files/conference/usenixsecurity16/sec16_paper_tramer.pdf)
* [Stiftung Neue Verantwortung: Securing Artificial Intelligence](https://www.stiftung-nv.de/en/node/2650)
* [The European Commissionâ€™s Artificial Intelligence Act](https://eur-lex.europa.eu/legal-content/EN/TXT/?qid=1623335154975&uri=CELEX%3A52021PC0206)
* [The European Commission Whitepaper: On Artificial Intelligence - A European approach to excellence and trust](https://ec.europa.eu/info/sites/default/files/commission-white-paper-artificial-intelligence-feb2020_en.pdf)
* [The current state of AI security and AI safety standards in China, with reference to international standards](https://cset.georgetown.edu/wp-content/uploads/t0121_AI_security_standardization_white_paper_EN.pdf)
* [Trustworthy Machine Learning course materials, Nicolas Papernot](https://www.papernot.fr/teaching/f21-trustworthy-ml.html)
